{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95e75369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prerequisites\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "663d5955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets number = 246\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import urllib\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/Chaoyuuu/Gather-Town-Datasets/master/datasets-real-room.json\"\n",
    "response = urllib.request.urlopen(url)\n",
    "data = json.loads(response.read())\n",
    "data_length = len(data)\n",
    "input_data = torch.zeros((data_length, 17, 13, 10))\n",
    "\n",
    "\n",
    "for i in range(data_length - 18):\n",
    "    for j in range(len(data[i][\"room\"])):\n",
    "        input_data[i][data[i][\"room\"][j][\"label\"]][data[i][\"room\"][j][\"y\"]][data[i][\"room\"][j][\"x\"]] = 1\n",
    "        if data[i][\"room\"][j][\"orientation\"] == 0:\n",
    "            input_data[i][16][data[i][\"room\"][j][\"y\"]][data[i][\"room\"][j][\"x\"]] = -1\n",
    "        elif data[i][\"room\"][j][\"orientation\"] == 1:\n",
    "            input_data[i][15][data[i][\"room\"][j][\"y\"]][data[i][\"room\"][j][\"x\"]] = -1\n",
    "        elif data[i][\"room\"][j][\"orientation\"] == 2:\n",
    "            input_data[i][16][data[i][\"room\"][j][\"y\"]][data[i][\"room\"][j][\"x\"]] = 1\n",
    "        else:\n",
    "            input_data[i][15][data[i][\"room\"][j][\"y\"]][data[i][\"room\"][j][\"x\"]] = 1\n",
    "\n",
    "\n",
    "\n",
    "z_dim = 4\n",
    "x_dim = 17*13*10\n",
    "bs = 64\n",
    "epoch_round = 20\n",
    "print(\"datasets number = \" + str(data_length))\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=input_data, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c231464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_dim, h_dim1, h_dim2, z_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # encoder part\n",
    "        self.fc1 = nn.Linear(x_dim, h_dim1)\n",
    "        self.fc2 = nn.Linear(h_dim1, h_dim2)\n",
    "        self.fc31 = nn.Linear(h_dim2, z_dim)\n",
    "        self.fc32 = nn.Linear(h_dim2, z_dim)\n",
    "        # decoder part\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim2)\n",
    "        self.fc5 = nn.Linear(h_dim2, h_dim1)\n",
    "        self.fc6 = nn.Linear(h_dim1, x_dim)\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        return self.fc31(h), self.fc32(h) # mu, log_var\n",
    "    \n",
    "    def sampling(self, mu, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add_(mu) # return z sample\n",
    "        \n",
    "    def decoder(self, z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        h = F.relu(self.fc5(h))\n",
    "        return torch.sigmoid(self.fc6(h)) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encoder(x.view(-1, x_dim))\n",
    "        z = self.sampling(mu, log_var)\n",
    "        return self.decoder(z), mu, log_var\n",
    "\n",
    "# build model\n",
    "vae = VAE(x_dim=x_dim, h_dim1= 512, h_dim2=256, z_dim=z_dim)\n",
    "if torch.cuda.is_available():\n",
    "    vae.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a5270d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (fc1): Linear(in_features=2210, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc31): Linear(in_features=256, out_features=4, bias=True)\n",
       "  (fc32): Linear(in_features=256, out_features=4, bias=True)\n",
       "  (fc4): Linear(in_features=4, out_features=256, bias=True)\n",
       "  (fc5): Linear(in_features=256, out_features=512, bias=True)\n",
       "  (fc6): Linear(in_features=512, out_features=2210, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "466a095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(vae.parameters())\n",
    "# return reconstruction error + KL divergence losses\n",
    "def loss_function(recon_x, x, mu, log_var):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, x_dim), reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37bcd4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    vae.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        data = data.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        print(list(data.size())) # [81, 17, 13, 10]\n",
    "        \n",
    "        recon_batch, mu, log_var = vae(data) #torch.float32\n",
    "        loss = loss_function(recon_batch, data, mu, log_var)\n",
    "        \n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item() / len(data)))\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c10d7873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    vae.eval()\n",
    "    test_loss= 0\n",
    "    with torch.no_grad():\n",
    "        for data, _ in test_loader:\n",
    "            data = data.cuda()\n",
    "            recon, mu, log_var = vae(data)\n",
    "            \n",
    "            # sum up batch loss\n",
    "            test_loss += loss_function(recon, data, mu, log_var).item()\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55d9592d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64, 17, 13, 10]\n",
      "Train Epoch: 1 [0/246 (0%)]\tLoss: 1535.265137\n",
      "[64, 17, 13, 10]\n",
      "[64, 17, 13, 10]\n",
      "[54, 17, 13, 10]\n",
      "====> Epoch: 1 Average loss: 1430.2245\n",
      "[64, 17, 13, 10]\n",
      "Train Epoch: 2 [0/246 (0%)]\tLoss: 1165.892090\n",
      "[64, 17, 13, 10]\n",
      "[64, 17, 13, 10]\n",
      "[54, 17, 13, 10]\n",
      "====> Epoch: 2 Average loss: 896.6375\n",
      "[64, 17, 13, 10]\n",
      "Train Epoch: 3 [0/246 (0%)]\tLoss: 413.064575\n",
      "[64, 17, 13, 10]\n",
      "[64, 17, 13, 10]\n",
      "[54, 17, 13, 10]\n",
      "====> Epoch: 3 Average loss: 240.0349\n",
      "[64, 17, 13, 10]\n",
      "Train Epoch: 4 [0/246 (0%)]\tLoss: 95.640297\n",
      "[64, 17, 13, 10]\n",
      "[64, 17, 13, 10]\n",
      "[54, 17, 13, 10]\n",
      "====> Epoch: 4 Average loss: 98.7035\n",
      "[64, 17, 13, 10]\n",
      "Train Epoch: 5 [0/246 (0%)]\tLoss: 68.399567\n",
      "[64, 17, 13, 10]\n",
      "[64, 17, 13, 10]\n",
      "[54, 17, 13, 10]\n",
      "====> Epoch: 5 Average loss: 34.9343\n",
      "[64, 17, 13, 10]\n",
      "Train Epoch: 6 [0/246 (0%)]\tLoss: -49.400143\n",
      "[64, 17, 13, 10]\n",
      "[64, 17, 13, 10]\n",
      "[54, 17, 13, 10]\n",
      "====> Epoch: 6 Average loss: -55.5873\n",
      "[64, 17, 13, 10]\n",
      "Train Epoch: 7 [0/246 (0%)]\tLoss: -105.834213\n",
      "[64, 17, 13, 10]\n",
      "[64, 17, 13, 10]\n",
      "[54, 17, 13, 10]\n",
      "====> Epoch: 7 Average loss: -129.4477\n",
      "[64, 17, 13, 10]\n",
      "Train Epoch: 8 [0/246 (0%)]\tLoss: -191.429474\n",
      "[64, 17, 13, 10]\n",
      "[64, 17, 13, 10]\n",
      "[54, 17, 13, 10]\n",
      "====> Epoch: 8 Average loss: -229.2021\n",
      "[64, 17, 13, 10]\n",
      "Train Epoch: 9 [0/246 (0%)]\tLoss: -298.125610\n",
      "[64, 17, 13, 10]\n",
      "[64, 17, 13, 10]\n",
      "[54, 17, 13, 10]\n",
      "====> Epoch: 9 Average loss: -308.4337\n",
      "[64, 17, 13, 10]\n",
      "Train Epoch: 10 [0/246 (0%)]\tLoss: -296.267731\n",
      "[64, 17, 13, 10]\n",
      "[64, 17, 13, 10]\n",
      "[54, 17, 13, 10]\n",
      "====> Epoch: 10 Average loss: -333.0911\n",
      "[64, 17, 13, 10]\n",
      "Train Epoch: 11 [0/246 (0%)]\tLoss: -354.790802\n",
      "[64, 17, 13, 10]\n",
      "[64, 17, 13, 10]\n",
      "[54, 17, 13, 10]\n",
      "====> Epoch: 11 Average loss: -314.1623\n",
      "[64, 17, 13, 10]\n",
      "Train Epoch: 12 [0/246 (0%)]\tLoss: -288.274597\n",
      "[64, 17, 13, 10]\n",
      "[64, 17, 13, 10]\n",
      "[54, 17, 13, 10]\n",
      "====> Epoch: 12 Average loss: -299.2353\n",
      "[64, 17, 13, 10]\n",
      "Train Epoch: 13 [0/246 (0%)]\tLoss: -284.376984\n",
      "[64, 17, 13, 10]\n",
      "[64, 17, 13, 10]\n",
      "[54, 17, 13, 10]\n",
      "====> Epoch: 13 Average loss: -335.9677\n",
      "[64, 17, 13, 10]\n",
      "Train Epoch: 14 [0/246 (0%)]\tLoss: -345.528961\n",
      "[64, 17, 13, 10]\n",
      "[64, 17, 13, 10]\n",
      "[54, 17, 13, 10]\n",
      "====> Epoch: 14 Average loss: -336.7660\n",
      "[64, 17, 13, 10]\n",
      "Train Epoch: 15 [0/246 (0%)]\tLoss: -333.302826\n",
      "[64, 17, 13, 10]\n",
      "[64, 17, 13, 10]\n",
      "[54, 17, 13, 10]\n",
      "====> Epoch: 15 Average loss: -322.7681\n",
      "[64, 17, 13, 10]\n",
      "Train Epoch: 16 [0/246 (0%)]\tLoss: -306.187744\n",
      "[64, 17, 13, 10]\n",
      "[64, 17, 13, 10]\n",
      "[54, 17, 13, 10]\n",
      "====> Epoch: 16 Average loss: -332.6153\n",
      "[64, 17, 13, 10]\n",
      "Train Epoch: 17 [0/246 (0%)]\tLoss: -329.799896\n",
      "[64, 17, 13, 10]\n",
      "[64, 17, 13, 10]\n",
      "[54, 17, 13, 10]\n",
      "====> Epoch: 17 Average loss: -361.3552\n",
      "[64, 17, 13, 10]\n",
      "Train Epoch: 18 [0/246 (0%)]\tLoss: -346.722565\n",
      "[64, 17, 13, 10]\n",
      "[64, 17, 13, 10]\n",
      "[54, 17, 13, 10]\n",
      "====> Epoch: 18 Average loss: -353.5716\n",
      "[64, 17, 13, 10]\n",
      "Train Epoch: 19 [0/246 (0%)]\tLoss: -356.695404\n",
      "[64, 17, 13, 10]\n",
      "[64, 17, 13, 10]\n",
      "[54, 17, 13, 10]\n",
      "====> Epoch: 19 Average loss: -336.2698\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epoch_round):\n",
    "    train(epoch)\n",
    "#     test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba9e979e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dup in 0, 0\n",
      "dup in 0, 4\n",
      "dup in 0, 9\n",
      "dup in 7, 6\n",
      "['LB', 'PP', '--', '--', 'TV', '--', 'B4', '--', 'PP', 'LB']\n",
      "['PP', '--', '--', '--', '--', '--', '--', '--', '--', '--']\n",
      "['--', '--', '--', '--', '--', '--', '--', '--', '--', '--']\n",
      "['--', '--', '--', 'CS', 'T3', '--', '--', 'CS', '--', '--']\n",
      "['--', '--', 'DC', 'CS', '--', '--', '--', 'CS', '--', '--']\n",
      "['--', '--', '--', 'CS', '--', '--', 'LP', 'CS', '--', '--']\n",
      "['--', '--', 'DC', 'CS', '--', '--', '--', 'CS', '--', '--']\n",
      "['--', '--', 'DC', 'CS', '--', '--', 'DC', 'CS', '--', '--']\n",
      "['--', '--', '--', 'CS', '--', '--', '--', 'CS', '--', '--']\n",
      "['PP', '--', '--', '--', '--', '--', '--', '--', '--', 'PP']\n",
      "['PP', '--', '--', '--', '--', '--', '--', '--', '--', 'PP']\n",
      "['--', '--', '--', '--', '--', '--', '--', '--', '--', 'PP']\n",
      "['--', '--', '--', '--', '--', '--', '--', '--', '--', '--']\n",
      "tensor([[8.8145e-03, 7.4729e-02, 6.6582e-02, 1.2192e-01, 2.1033e-01, 1.0887e-01,\n",
      "         5.3007e-02, 3.9349e-02, 2.2622e-02, 1.1929e-07, 1.3852e-07, 5.0939e-08,\n",
      "         1.0718e-02, 2.5878e-02, 3.3945e-02, 1.6466e-07, 1.4028e-02, 1.4978e-07,\n",
      "         1.9794e-02, 1.8294e-07, 1.7784e-02, 1.3685e-02, 9.5801e-08, 3.1433e-02,\n",
      "         9.0237e-02, 7.5185e-02, 1.1296e-02, 9.8759e-03, 1.4346e-02, 3.0255e-07,\n",
      "         1.5528e-07, 2.9569e-07, 1.4201e-07, 1.4962e-07, 2.0410e-02, 7.9166e-08,\n",
      "         2.1738e-07, 1.1066e-07, 6.0697e-08, 1.2529e-07, 3.4397e-07, 2.9188e-07,\n",
      "         2.0587e-07, 2.6366e-07, 3.8605e-07, 7.0553e-08, 3.2299e-07, 1.3767e-07,\n",
      "         1.2641e-07, 2.9722e-07, 1.5180e-07, 7.8713e-03, 1.9024e-07, 8.9637e-08,\n",
      "         1.5360e-07, 5.4642e-08, 1.3484e-07, 2.8187e-07, 3.7017e-07, 1.1078e-07,\n",
      "         7.3026e-08, 1.9907e-07, 3.7381e-07, 1.7261e-07, 4.7695e-07, 2.8356e-07,\n",
      "         2.9530e-07, 1.1449e-07, 2.5810e-07, 1.1435e-07, 1.6022e-07, 3.2737e-07,\n",
      "         9.0291e-07, 1.4603e-07, 1.4123e-07, 2.2441e-07, 1.3008e-07, 3.5354e-07,\n",
      "         2.1107e-07, 8.4259e-08, 1.1292e-07, 2.0604e-07, 6.9597e-08, 1.8461e-07,\n",
      "         1.4737e-07, 1.7029e-07, 1.0674e-07, 1.0457e-07, 2.2779e-08, 1.6895e-07,\n",
      "         1.3865e-07, 1.5511e-07, 1.8401e-07, 1.8026e-07, 3.4748e-08, 1.7851e-07,\n",
      "         9.1458e-08, 1.6993e-07, 1.2330e-07, 1.6731e-07, 1.7806e-07, 1.6932e-07,\n",
      "         1.9011e-07, 2.0775e-07, 7.1122e-08, 2.4451e-07, 9.1485e-08, 1.4451e-07,\n",
      "         1.8460e-07, 3.2492e-07, 4.1945e-07, 3.6599e-07, 4.2393e-08, 5.7763e-08,\n",
      "         8.4128e-08, 1.6289e-07, 8.0476e-08, 5.0069e-08, 2.1404e-07, 1.1273e-07,\n",
      "         1.5109e-07, 2.0243e-07, 2.1511e-07, 1.5539e-07, 6.3098e-07, 1.3211e-07,\n",
      "         8.3099e-08, 1.8507e-07, 3.2154e-07, 1.5778e-07, 8.5756e-08, 5.0958e-02,\n",
      "         2.8069e-02, 3.9246e-02, 7.3013e-02, 3.4126e-02, 8.4671e-02, 7.5255e-03,\n",
      "         3.3880e-07, 1.1455e-07, 9.9719e-08, 2.7863e-07, 1.4191e-02, 9.6500e-03,\n",
      "         1.7071e-07, 6.7657e-03, 1.3742e-07, 4.2933e-07, 3.9140e-07, 2.0004e-07,\n",
      "         2.2599e-07, 6.7688e-08, 1.3721e-02, 1.0390e-07, 1.3168e-07, 8.1483e-03,\n",
      "         1.8540e-02, 1.4322e-07, 2.3033e-07, 5.7516e-07, 8.8106e-08, 4.2498e-07,\n",
      "         2.4334e-07, 1.6941e-07, 4.5234e-08, 2.6380e-07, 5.4420e-07, 3.5639e-07,\n",
      "         1.3240e-07, 8.0485e-08, 3.2053e-08, 6.8101e-08, 2.5215e-07, 2.0462e-07,\n",
      "         4.9177e-08, 1.6787e-07, 8.4675e-08, 4.1004e-08, 8.4568e-08, 1.5423e-07,\n",
      "         1.9467e-07, 2.8177e-07, 8.0205e-08, 1.0497e-07, 4.3744e-07, 1.4317e-02,\n",
      "         3.1321e-07, 1.9900e-07, 3.1960e-07, 7.7517e-08, 2.5184e-07, 1.9545e-07,\n",
      "         8.8584e-08, 2.5062e-07, 1.7816e-07, 2.0407e-07, 2.5514e-07, 7.6645e-08,\n",
      "         1.1641e-07, 1.2500e-07, 2.1436e-07, 1.2072e-07, 1.8859e-07, 1.9360e-07,\n",
      "         1.8122e-07, 1.5132e-07, 5.2677e-07, 3.1086e-07, 3.2422e-07, 1.7489e-07,\n",
      "         2.3594e-07, 4.0555e-08, 1.0878e-07, 1.5146e-07, 1.2786e-07, 1.0667e-06,\n",
      "         2.1612e-07, 1.8253e-07, 1.4633e-07, 2.6482e-07, 8.3697e-08, 8.4348e-08,\n",
      "         4.2850e-08, 1.3590e-02, 2.8126e-07, 6.4294e-08, 4.0043e-07, 1.0361e-07,\n",
      "         5.0843e-07, 1.6349e-07, 1.4889e-07, 1.8998e-07, 1.4422e-07, 4.9449e-08,\n",
      "         2.1030e-07, 1.7470e-07, 1.8889e-07, 2.0077e-07, 2.7069e-07, 1.5095e-07,\n",
      "         2.0751e-07, 1.6952e-07, 1.2360e-07, 9.4502e-08, 4.1540e-07, 2.8314e-07,\n",
      "         4.5567e-08, 8.0421e-08, 2.6979e-07, 1.0641e-07, 2.8640e-07, 2.1861e-07,\n",
      "         1.6707e-02, 2.0640e-07, 1.0539e-07, 1.2378e-07, 2.9212e-07, 7.0998e-08,\n",
      "         2.4349e-07, 6.3549e-08, 2.7501e-07, 1.2558e-07, 1.1027e-07, 2.1471e-07,\n",
      "         1.8978e-07, 2.6119e-07, 2.2483e-07, 7.4306e-08, 2.1294e-07, 1.7696e-07,\n",
      "         1.3987e-07, 6.8795e-08, 1.5175e-07, 9.3991e-08, 2.9534e-07, 4.3747e-07,\n",
      "         1.7541e-07, 2.7849e-08, 1.1263e-07, 1.4578e-07, 3.2533e-08, 1.9583e-07,\n",
      "         2.5741e-07, 1.4340e-07, 3.2279e-02, 1.7246e-02, 1.0545e-02, 7.5731e-08,\n",
      "         2.5261e-07, 1.3859e-07, 7.5388e-08, 1.1516e-07, 2.3481e-02, 1.3990e-01,\n",
      "         7.3853e-02, 4.4624e-02, 2.0297e-02, 2.1488e-07, 7.0175e-08, 2.8495e-07,\n",
      "         1.2012e-07, 8.8178e-03, 1.3297e-02, 1.0908e-01, 9.9323e-02, 9.8299e-02,\n",
      "         1.1184e-02, 1.6010e-07, 5.9123e-03, 2.6611e-07, 1.5074e-07, 1.0899e-02,\n",
      "         6.4871e-02, 8.6477e-02, 9.6617e-02, 8.7374e-02, 6.1580e-02, 1.5538e-07,\n",
      "         4.3870e-08, 1.4218e-07, 1.1926e-07, 5.1724e-08, 1.1622e-02, 8.0796e-02,\n",
      "         8.7781e-02, 4.1351e-02, 2.9860e-03, 1.0487e-07, 1.3741e-07, 2.6255e-07,\n",
      "         2.0185e-07, 2.8816e-03, 2.6850e-02, 1.1338e-01, 7.8938e-02, 8.1368e-02,\n",
      "         3.0813e-02, 2.9821e-03, 2.2196e-03, 5.1247e-07, 1.6100e-07, 6.6896e-07,\n",
      "         7.0132e-08, 3.3524e-02, 6.5885e-03, 2.6357e-07, 1.5204e-07, 2.2023e-07,\n",
      "         1.5656e-07, 1.7388e-07, 9.6805e-08, 2.6369e-07, 2.9521e-07, 4.9456e-08,\n",
      "         3.6466e-07, 2.1492e-07, 1.3783e-07, 2.2626e-07, 7.2502e-08, 9.8144e-08,\n",
      "         1.0799e-07, 5.6198e-08, 4.8871e-08, 9.2048e-08, 8.5057e-08, 7.8693e-08,\n",
      "         1.1992e-07, 2.8330e-07, 1.0591e-07, 1.2163e-07, 1.3596e-07, 1.4308e-07,\n",
      "         3.3682e-07, 9.8423e-08, 1.2014e-07, 4.4885e-08, 1.1423e-07, 2.0927e-07,\n",
      "         9.7251e-08, 3.4710e-07, 1.5017e-07, 1.3739e-07, 1.6872e-07, 1.8736e-07,\n",
      "         1.2978e-07, 8.3400e-08, 1.1051e-07, 1.0969e-07, 1.4676e-07, 2.3072e-07,\n",
      "         1.5193e-07, 2.7362e-02, 6.6819e-02, 6.6606e-02, 1.9674e-01, 1.0069e-01,\n",
      "         9.1928e-02, 3.4687e-02, 1.0830e-07, 1.3896e-07, 1.9400e-07, 2.7473e-07,\n",
      "         1.8535e-07, 2.4663e-07, 1.5778e-07, 1.1946e-07, 2.2449e-07, 4.4679e-07,\n",
      "         7.9177e-08, 9.0894e-08, 2.9125e-07, 7.7439e-08, 1.5501e-07, 3.1790e-07,\n",
      "         4.4382e-07, 1.1167e-07, 1.6388e-07, 1.3749e-07, 2.8191e-07, 2.1880e-07,\n",
      "         1.6208e-07, 1.5832e-07, 1.6676e-07, 5.7994e-08, 6.5241e-08, 9.8880e-08,\n",
      "         2.4362e-07, 6.2103e-08, 1.8056e-07, 4.4595e-07, 8.8102e-08, 2.2091e-07,\n",
      "         6.6440e-08, 1.4036e-07, 6.4961e-08, 2.7341e-07, 7.1046e-08, 3.5296e-08,\n",
      "         1.4549e-07, 1.1893e-07, 1.8059e-07, 4.0575e-07, 4.6936e-08, 5.2856e-07,\n",
      "         5.0456e-08, 3.3037e-07, 9.6942e-08, 4.2905e-07, 1.3809e-07, 3.2290e-07,\n",
      "         1.2850e-07, 2.3982e-07, 1.3722e-07, 1.9125e-07, 1.1898e-07, 2.8979e-08,\n",
      "         2.6008e-07, 6.0296e-08, 3.1079e-07, 9.4853e-08, 7.4780e-08, 8.3072e-08,\n",
      "         2.3575e-07, 1.3359e-07, 4.9224e-08, 1.0701e-07, 1.0189e-07, 2.6557e-07,\n",
      "         1.0787e-07, 7.4597e-08, 2.1108e-07, 1.5829e-07, 7.7857e-08, 6.0279e-08,\n",
      "         1.5203e-07, 4.9288e-07, 1.4394e-07, 9.8239e-08, 1.9869e-07, 1.5614e-07,\n",
      "         2.1942e-07, 4.2142e-08, 2.0795e-07, 1.8494e-07, 2.2373e-07, 1.5503e-07,\n",
      "         7.0936e-08, 1.2385e-07, 1.4953e-07, 4.2827e-07, 2.1667e-07, 1.3809e-07,\n",
      "         2.6584e-07, 6.7040e-08, 2.5377e-07, 2.7948e-07, 4.0255e-07, 3.7097e-08,\n",
      "         2.3876e-07, 1.2885e-07, 1.9990e-07, 1.9338e-07, 7.4119e-08, 1.5089e-07,\n",
      "         4.6377e-08, 2.4200e-08, 9.9720e-08, 9.6943e-08, 2.8477e-07, 1.0119e-07,\n",
      "         1.3087e-07, 1.4682e-07, 1.8531e-07, 1.3946e-07, 4.8225e-08, 9.8025e-08,\n",
      "         1.1453e-07, 1.6903e-07, 1.3088e-07, 1.3032e-07, 2.4993e-01, 7.4719e-02,\n",
      "         6.4153e-02, 7.4056e-02, 7.7125e-02, 8.3927e-02, 1.6975e-01, 3.4098e-07,\n",
      "         1.6882e-07, 1.1789e-02, 9.9444e-03, 1.6035e-07, 3.1751e-08, 2.6725e-07,\n",
      "         6.0698e-08, 3.5392e-07, 1.6562e-08, 3.6981e-07, 5.7162e-08, 2.9577e-02,\n",
      "         3.4339e-02, 1.0206e-07, 4.7611e-08, 4.0911e-07, 1.4892e-07, 9.8697e-08,\n",
      "         7.5572e-08, 3.2414e-07, 3.9032e-07, 3.0068e-02, 5.4285e-02, 1.7246e-07,\n",
      "         2.0092e-07, 2.0914e-07, 9.3458e-08, 1.2301e-07, 2.8738e-07, 4.3517e-07,\n",
      "         1.7688e-07, 3.0562e-02, 5.9272e-02, 1.8578e-07, 3.1833e-07, 2.1631e-07,\n",
      "         1.8057e-07, 3.1339e-07, 1.4854e-07, 7.5989e-08, 5.8323e-08, 8.8975e-03,\n",
      "         9.7838e-03, 2.5195e-07, 2.5153e-07, 1.5253e-07, 1.0224e-07, 2.7749e-07,\n",
      "         1.5182e-07, 1.4899e-07, 1.5288e-07, 4.3570e-02, 1.5282e-02, 9.7091e-08,\n",
      "         1.3535e-07, 3.2500e-07, 3.6989e-07, 1.7040e-07, 1.1695e-07, 2.0842e-07,\n",
      "         7.9921e-07, 2.1535e-02, 4.3739e-02, 1.1756e-07, 2.1692e-07, 7.0295e-08,\n",
      "         1.7417e-07, 6.1435e-08, 9.6445e-08, 2.1820e-07, 1.3912e-07, 1.7047e-02,\n",
      "         4.3375e-02, 1.0191e-07, 2.2507e-07, 5.7320e-08, 7.7568e-08, 8.5423e-08,\n",
      "         6.7433e-08, 3.5206e-08, 2.7401e-07, 3.7100e-02, 2.9710e-07, 1.8322e-07,\n",
      "         9.1429e-08, 1.7619e-02, 1.2378e-07, 1.0450e-07, 5.7932e-08, 2.3537e-07,\n",
      "         1.1238e-07, 1.2153e-07, 1.7036e-07, 8.4361e-08, 1.2310e-07, 3.6060e-08,\n",
      "         4.8267e-07, 1.2584e-07, 5.8637e-07, 3.7034e-08, 1.9199e-07, 7.3782e-08,\n",
      "         1.8626e-07, 1.7155e-07, 2.4770e-02, 1.4633e-07, 2.3622e-07, 1.7902e-07,\n",
      "         6.2938e-02, 1.2626e-07, 2.0574e-07, 1.7744e-07, 7.0699e-08, 3.4241e-07,\n",
      "         4.8938e-08, 1.2417e-07, 2.9524e-07, 1.2821e-07, 3.0102e-07, 2.5504e-07,\n",
      "         1.8256e-07, 1.0893e-07, 3.2072e-01, 1.6341e-01, 4.2435e-02, 1.6211e-02,\n",
      "         2.9542e-02, 3.6054e-02, 3.2516e-02, 4.6753e-02, 2.1755e-01, 3.2684e-01,\n",
      "         1.7098e-01, 1.5128e-07, 1.0078e-07, 1.8019e-07, 3.3037e-07, 1.6041e-07,\n",
      "         2.4767e-07, 6.8839e-08, 3.6348e-07, 1.3006e-01, 9.4236e-02, 1.5631e-07,\n",
      "         1.3337e-07, 2.4908e-07, 2.1839e-07, 6.8704e-08, 4.1363e-07, 1.2359e-07,\n",
      "         3.6334e-08, 6.8444e-02, 6.8522e-02, 1.2540e-07, 1.6917e-07, 1.7364e-07,\n",
      "         8.9158e-08, 2.0135e-07, 1.3079e-07, 1.3038e-07, 1.0819e-07, 3.3616e-02,\n",
      "         2.8601e-02, 1.4556e-07, 1.9123e-07, 1.4130e-07, 1.7575e-07, 1.6467e-07,\n",
      "         7.1531e-08, 2.1497e-07, 7.2406e-08, 2.1532e-02, 6.5162e-02, 1.1483e-07,\n",
      "         1.4355e-07, 1.7437e-07, 1.6732e-07, 1.1043e-07, 8.6729e-08, 9.0568e-08,\n",
      "         2.4076e-07, 2.9311e-02, 6.2309e-02, 1.5776e-07, 8.0914e-08, 2.7073e-07,\n",
      "         1.6170e-07, 1.5532e-07, 8.9374e-08, 2.5361e-07, 1.5715e-07, 3.3331e-02,\n",
      "         5.9263e-02, 5.3364e-08, 8.9696e-08, 7.3268e-08, 6.7880e-07, 5.2840e-07,\n",
      "         2.8306e-07, 6.1609e-07, 2.2349e-07, 2.8155e-02, 4.9109e-02, 4.0471e-08,\n",
      "         3.2923e-08, 3.6450e-07, 4.0060e-08, 7.6539e-08, 1.1737e-07, 1.2177e-07,\n",
      "         3.4384e-07, 3.3887e-02, 1.7351e-01, 2.8927e-07, 2.8843e-07, 2.5730e-07,\n",
      "         2.8725e-07, 5.3453e-07, 1.3403e-07, 5.5284e-08, 8.8501e-08, 1.5836e-01,\n",
      "         3.2261e-01, 1.0938e-02, 7.6898e-08, 9.5690e-08, 2.6170e-07, 1.7547e-07,\n",
      "         1.0136e-07, 1.4179e-07, 5.5533e-02, 3.0359e-01, 7.4554e-02, 1.1074e-02,\n",
      "         3.4473e-02, 1.0190e-02, 5.5699e-02, 6.1882e-02, 6.9419e-02, 1.1557e-01,\n",
      "         1.2124e-01, 1.7055e-01, 7.0993e-08, 9.3845e-08, 1.2402e-07, 1.6365e-07,\n",
      "         4.2093e-07, 2.2389e-07, 1.7833e-07, 2.1427e-07, 6.6844e-08, 1.2447e-07,\n",
      "         1.4331e-07, 1.6095e-07, 2.4052e-07, 1.4360e-07, 2.0147e-07, 7.2061e-08,\n",
      "         3.5976e-07, 1.4809e-07, 7.6290e-07, 1.9200e-07, 6.5406e-08, 1.4807e-07,\n",
      "         2.0056e-07, 1.6493e-07, 1.3173e-07, 9.5193e-08, 9.1702e-08, 1.9833e-07,\n",
      "         2.2444e-07, 8.9618e-08, 2.0962e-07, 1.4984e-07, 2.5100e-02, 3.6062e-02,\n",
      "         3.8205e-02, 8.6183e-03, 2.8827e-02, 3.4840e-02, 3.5834e-02, 1.2733e-02,\n",
      "         1.6219e-02, 1.5303e-02, 2.6756e-02, 2.3510e-02, 7.5316e-02, 8.6082e-02,\n",
      "         1.4143e-02, 2.4316e-02, 4.3634e-02, 8.2984e-03, 1.2649e-02, 1.4038e-02,\n",
      "         1.3555e-02, 7.5699e-02, 2.8266e-02, 2.4825e-02, 6.5552e-02, 3.1390e-02,\n",
      "         6.4904e-02, 9.1641e-03, 1.8683e-02, 3.6365e-02, 6.2555e-02, 7.1377e-02,\n",
      "         3.4991e-02, 1.3493e-02, 4.3933e-02, 5.5977e-02, 7.4974e-02, 1.1119e-02,\n",
      "         1.4126e-02, 3.2936e-02, 7.1902e-02, 3.5395e-02, 3.5695e-02, 2.0759e-02,\n",
      "         3.3500e-02, 8.8267e-02, 1.0355e-01, 1.0750e-07, 2.1084e-02, 9.1062e-03,\n",
      "         4.8113e-02, 6.3456e-02, 3.7247e-02, 2.4450e-02, 4.8124e-02, 5.8346e-02,\n",
      "         3.8828e-02, 1.8923e-07, 9.7374e-03, 9.2967e-08, 4.0978e-02, 6.0659e-02,\n",
      "         8.4622e-02, 7.3140e-02, 8.5338e-02, 4.1469e-02, 2.2038e-02, 1.4695e-07,\n",
      "         6.4260e-03, 1.4054e-07, 2.5169e-02, 3.9300e-02, 2.5281e-02, 3.9667e-02,\n",
      "         2.7560e-02, 8.7076e-08, 2.3189e-07, 1.4754e-07, 8.3600e-08, 1.5428e-07,\n",
      "         1.2859e-02, 1.5447e-07, 1.5990e-02, 9.3433e-03, 1.5487e-07, 4.8032e-08,\n",
      "         4.8103e-08, 3.4924e-07, 2.1996e-07, 2.1538e-07, 1.4314e-07, 1.7570e-07,\n",
      "         3.1278e-07, 6.9847e-08, 1.1831e-07, 1.4550e-07, 1.6026e-07, 6.4118e-08,\n",
      "         6.6802e-08, 1.2185e-07, 1.7480e-07, 9.3133e-08, 1.6355e-07, 1.5950e-07,\n",
      "         1.5448e-07, 1.8864e-07, 2.3771e-07, 1.8224e-07, 6.3248e-08, 4.0726e-07,\n",
      "         8.4473e-08, 1.2305e-07, 2.3962e-07, 9.1506e-08, 1.4017e-07, 1.3856e-07,\n",
      "         1.3292e-07, 5.2311e-08, 7.1353e-07, 3.5664e-07, 3.2975e-07, 4.3819e-08,\n",
      "         1.6727e-07, 1.3463e-02, 1.2470e-07, 2.2691e-07, 1.7393e-07, 8.4805e-08,\n",
      "         9.8261e-03, 1.9646e-07, 7.6151e-03, 2.7308e-07, 1.4930e-07, 9.2603e-03,\n",
      "         1.0068e-07, 9.4869e-08, 4.5063e-07, 2.7749e-02, 2.7380e-02, 4.7648e-07,\n",
      "         8.5310e-08, 1.8367e-02, 3.7852e-02, 2.6656e-02, 1.4994e-02, 3.4719e-07,\n",
      "         4.9620e-08, 2.5464e-02, 2.8135e-02, 3.2459e-07, 8.9222e-03, 2.1069e-02,\n",
      "         3.5451e-02, 1.5667e-02, 3.1338e-02, 1.1155e-02, 9.4551e-08, 2.5250e-02,\n",
      "         3.6646e-02, 8.9093e-03, 2.5015e-02, 9.1916e-08, 7.2897e-08, 2.8541e-03,\n",
      "         1.1259e-02, 1.1454e-02, 3.1478e-02, 1.6510e-02, 3.2780e-02, 3.5649e-02,\n",
      "         4.3133e-02, 4.8255e-02, 1.2871e-07, 1.5075e-02, 1.1983e-02, 1.2311e-02,\n",
      "         5.9260e-02, 1.3468e-02, 1.6532e-02, 1.8207e-07, 1.1893e-02, 2.2920e-02,\n",
      "         3.5449e-02, 3.1618e-02, 3.0891e-02, 1.7225e-02, 1.6943e-02, 2.1772e-02,\n",
      "         1.8287e-02, 5.7649e-08, 2.4862e-07, 7.1957e-02, 2.7900e-02, 1.1151e-02,\n",
      "         9.6721e-02, 1.0778e-02, 1.0875e-07, 1.9742e-02, 1.2433e-02, 2.3894e-07,\n",
      "         8.4932e-08, 1.5062e-02, 2.4858e-02, 3.2890e-02, 2.9178e-02, 1.5443e-07,\n",
      "         2.2732e-07, 2.3384e-02, 1.0225e-02, 1.3181e-07, 1.7758e-07, 1.3121e-07,\n",
      "         2.8155e-02, 1.1650e-02, 6.4351e-08, 2.2093e-07, 1.8656e-07, 9.6376e-03,\n",
      "         1.6954e-07, 3.6050e-07, 9.6762e-08, 1.2983e-07, 5.3861e-03, 2.5393e-07,\n",
      "         8.6447e-03, 1.4957e-02, 2.3556e-07, 1.1050e-02, 5.4111e-08, 2.4506e-07,\n",
      "         3.4192e-07, 2.0694e-07, 1.2880e-07, 3.2529e-07, 1.1313e-07, 1.4826e-07,\n",
      "         1.4606e-07, 3.3555e-07, 3.6174e-07, 2.8116e-07, 2.0087e-07, 1.7836e-07,\n",
      "         6.2043e-08, 8.2800e-08, 2.1608e-07, 7.5966e-08, 1.2429e-07, 4.5280e-08,\n",
      "         1.9407e-07, 2.4171e-08, 1.6374e-02, 3.1296e-02, 3.7818e-07, 2.2859e-07,\n",
      "         3.3009e-02, 2.4071e-07, 4.7734e-07, 1.5421e-07, 1.4072e-07, 1.3613e-07,\n",
      "         3.4444e-02, 8.0093e-02, 6.9297e-08, 3.3450e-02, 6.3522e-02, 5.7426e-02,\n",
      "         1.1176e-02, 9.4082e-08, 2.9661e-07, 2.9113e-02, 7.8678e-02, 1.8699e-01,\n",
      "         5.6351e-02, 6.3042e-02, 1.0559e-01, 1.8349e-01, 5.4047e-02, 3.8725e-08,\n",
      "         7.4613e-03, 5.4043e-02, 1.2634e-01, 2.7059e-01, 4.7500e-02, 5.6708e-02,\n",
      "         1.3370e-01, 2.8499e-01, 6.6320e-02, 1.3420e-02, 7.9240e-03, 5.0639e-02,\n",
      "         1.0361e-01, 2.7784e-01, 6.0853e-02, 6.5361e-02, 1.0698e-01, 2.3495e-01,\n",
      "         6.6087e-02, 2.5669e-02, 9.6190e-03, 3.7961e-02, 8.0806e-02, 2.3526e-01,\n",
      "         5.8384e-02, 3.7927e-02, 1.1328e-01, 2.0614e-01, 5.9461e-02, 1.9931e-02,\n",
      "         9.8208e-03, 3.5567e-02, 8.0689e-02, 2.3006e-01, 5.7077e-02, 4.2676e-02,\n",
      "         1.0320e-01, 1.8864e-01, 7.4676e-02, 1.9068e-02, 1.2960e-02, 3.8862e-02,\n",
      "         7.1268e-02, 1.8773e-01, 8.1974e-02, 3.3428e-02, 8.6473e-02, 1.7204e-01,\n",
      "         6.5611e-02, 5.2789e-03, 1.3943e-02, 1.5712e-02, 6.7512e-02, 9.9389e-02,\n",
      "         3.9031e-02, 3.6640e-02, 7.0160e-02, 1.1557e-01, 3.2042e-02, 2.5247e-03,\n",
      "         1.3948e-07, 2.0263e-07, 1.5704e-02, 3.2838e-02, 7.7515e-03, 9.0089e-03,\n",
      "         1.0804e-02, 4.3695e-02, 1.2381e-07, 5.7639e-08, 5.7665e-08, 5.9624e-08,\n",
      "         2.3743e-07, 1.1526e-07, 2.4636e-07, 1.2612e-07, 2.7106e-07, 1.4918e-07,\n",
      "         1.6534e-07, 7.6035e-08, 1.6935e-07, 6.3155e-08, 5.3629e-08, 8.4743e-08,\n",
      "         6.5181e-03, 1.4177e-02, 1.5004e-02, 1.2722e-02, 1.8859e-07, 7.2562e-08,\n",
      "         8.7228e-08, 5.3692e-07, 2.3290e-07, 3.8804e-07, 1.7753e-07, 1.0554e-07,\n",
      "         2.3268e-07, 1.7319e-07, 2.6960e-07, 1.4047e-07, 1.6307e-07, 2.8205e-07,\n",
      "         3.5907e-07, 1.5733e-07, 1.1030e-07, 4.4843e-07, 7.9168e-07, 1.1052e-07,\n",
      "         1.0177e-07, 6.4109e-08, 2.3544e-07, 1.1072e-02, 2.1918e-07, 3.9156e-02,\n",
      "         4.7641e-02, 1.4232e-02, 3.4264e-07, 8.2579e-08, 8.0022e-08, 2.4162e-07,\n",
      "         1.2509e-07, 3.0155e-03, 5.1035e-02, 3.4573e-02, 1.6058e-01, 9.7983e-02,\n",
      "         1.8862e-07, 1.0464e-07, 9.6916e-08, 8.7617e-08, 3.4554e-07, 1.1163e-02,\n",
      "         1.3257e-02, 6.7589e-02, 9.3677e-02, 1.2079e-07, 1.4569e-02, 4.1592e-08,\n",
      "         9.9571e-08, 1.4399e-07, 7.6674e-08, 1.4013e-02, 8.9647e-02, 9.3257e-02,\n",
      "         7.0577e-02, 1.0973e-01, 3.1785e-02, 1.4411e-07, 2.4021e-07, 1.9646e-07,\n",
      "         1.4146e-07, 2.0954e-03, 1.2289e-02, 3.8442e-02, 1.1759e-01, 5.1022e-02,\n",
      "         1.8968e-07, 2.3178e-07, 6.5119e-08, 5.6369e-07, 3.6273e-07, 1.2006e-02,\n",
      "         1.5921e-02, 7.1002e-02, 9.7067e-02, 3.0891e-02, 2.4935e-03, 1.0811e-07,\n",
      "         5.2160e-08, 6.2276e-08, 1.3818e-07, 6.4357e-08, 1.3266e-07, 3.7520e-02,\n",
      "         3.5210e-02, 1.0423e-07, 3.3629e-07, 1.4101e-07, 1.0275e-07, 3.1110e-07,\n",
      "         8.1866e-08, 1.0061e-07, 5.3046e-08, 1.9001e-07, 2.7905e-07, 1.8259e-07,\n",
      "         8.1097e-08, 1.4298e-07, 1.0074e-06, 3.7057e-07, 6.1107e-08, 1.5414e-07,\n",
      "         1.9420e-07, 1.8010e-07, 1.3747e-07, 1.4951e-07, 8.0110e-08, 1.1597e-07,\n",
      "         1.5229e-07, 2.6737e-07, 1.6801e-07, 1.8377e-07, 4.4274e-08, 1.8159e-07,\n",
      "         3.4063e-07, 8.4757e-08, 5.4240e-08, 2.9244e-07, 1.7622e-07, 1.7119e-07,\n",
      "         1.9688e-07, 9.0307e-08, 9.9951e-08, 2.1568e-07, 2.4353e-07, 2.8311e-07,\n",
      "         2.4530e-07, 7.0507e-08, 3.5501e-07, 1.4978e-07, 1.1367e-01, 1.1765e-01,\n",
      "         2.8433e-02, 8.7843e-03, 1.5835e-02, 1.0101e-02, 9.5734e-08, 1.2196e-02,\n",
      "         7.5134e-02, 8.3304e-02, 1.0877e-02, 1.8001e-07, 2.1251e-07, 2.2142e-07,\n",
      "         3.0808e-07, 5.3586e-08, 1.1021e-07, 1.7658e-07, 1.8741e-07, 1.0219e-02,\n",
      "         3.7686e-02, 1.1298e-07, 2.6398e-07, 5.3069e-08, 9.1316e-08, 1.6638e-07,\n",
      "         3.6710e-07, 1.2094e-07, 5.2863e-07, 4.1791e-03, 2.7579e-07, 3.3877e-07,\n",
      "         3.1416e-07, 1.3003e-07, 3.6644e-07, 1.3799e-07, 4.5381e-07, 1.8358e-07,\n",
      "         1.7289e-07, 4.4073e-03, 3.5069e-02, 1.6838e-07, 6.1637e-08, 1.5802e-07,\n",
      "         1.2300e-07, 1.4825e-07, 2.0979e-07, 9.2673e-08, 1.3600e-07, 8.7107e-03,\n",
      "         3.1618e-02, 2.4040e-07, 3.8407e-07, 3.0563e-07, 2.1470e-07, 1.3073e-07,\n",
      "         1.0036e-07, 1.5821e-07, 1.8381e-07, 2.9975e-02, 3.2702e-02, 1.1023e-07,\n",
      "         1.4077e-07, 2.2840e-07, 3.7433e-08, 1.5772e-07, 1.5438e-07, 6.9577e-08,\n",
      "         3.2084e-07, 2.3600e-02, 2.5228e-02, 5.0967e-07, 5.9129e-08, 1.1386e-07,\n",
      "         2.0868e-07, 2.4564e-07, 3.3087e-07, 1.3464e-07, 1.1864e-07, 2.7793e-02,\n",
      "         8.8200e-03, 1.6666e-07, 7.2854e-08, 1.5071e-07, 1.8266e-07, 3.7847e-07,\n",
      "         1.1185e-07, 1.8000e-07, 2.7785e-07, 2.3648e-02, 1.0059e-02, 1.2777e-07,\n",
      "         4.2045e-07, 8.0307e-08, 2.5469e-07, 9.1577e-08, 2.4790e-07, 8.4336e-08,\n",
      "         3.7304e-07, 5.1056e-02, 3.8493e-03, 2.2437e-07, 2.0762e-07, 5.5165e-07,\n",
      "         2.9375e-07, 1.3299e-07, 1.3074e-07, 1.7083e-07, 1.3344e-07, 3.4766e-02,\n",
      "         2.6324e-07, 2.1520e-07, 1.5995e-07, 9.6186e-08, 1.1161e-07, 6.8749e-08,\n",
      "         1.0268e-06, 1.1303e-07, 3.7459e-07, 1.2449e-02, 5.3419e-08, 8.2405e-08,\n",
      "         2.7536e-07, 1.5137e-07, 1.7013e-07, 1.1275e-07, 7.1950e-08, 1.7438e-07,\n",
      "         8.7599e-08, 2.0854e-07, 7.8071e-08, 9.6204e-08, 1.4633e-07, 3.9715e-07,\n",
      "         1.6476e-07, 2.5676e-07, 1.3157e-07, 3.9351e-07, 1.4705e-07, 8.6178e-08,\n",
      "         2.6972e-07, 7.8563e-08, 1.9368e-07, 1.7032e-07, 1.6351e-07, 1.7122e-07,\n",
      "         1.9104e-07, 1.0435e-07, 1.5120e-08, 1.5596e-07, 2.1606e-07, 1.6332e-07,\n",
      "         5.7161e-08, 1.7492e-07, 2.1033e-07, 1.0761e-02, 1.7610e-02, 1.8168e-07,\n",
      "         6.3625e-08, 2.2774e-07, 1.0317e-07, 1.9487e-07, 6.8940e-07, 2.8705e-02,\n",
      "         1.1806e-02, 1.2024e-02, 2.5238e-02, 1.2707e-02, 1.7124e-07, 8.6982e-08,\n",
      "         1.2595e-07, 2.5343e-07, 4.6522e-08, 2.6838e-02, 8.6549e-02, 8.9111e-02,\n",
      "         6.3522e-02, 3.2398e-02, 1.7547e-07, 1.7340e-07, 2.2249e-07, 8.8836e-03,\n",
      "         1.6162e-07, 1.3203e-01, 9.1772e-02, 6.9755e-02, 1.9716e-01, 2.9582e-02,\n",
      "         2.7701e-03, 1.2309e-07, 3.8302e-07, 2.1606e-07, 4.1311e-02, 5.7814e-02,\n",
      "         6.1177e-02, 5.9043e-02, 1.0285e-01, 3.9913e-02, 1.5966e-07, 3.9206e-07,\n",
      "         2.3994e-07, 2.8041e-07, 1.0641e-02, 9.8838e-02, 7.6854e-02, 5.3656e-02,\n",
      "         1.6331e-01, 2.6700e-02, 1.8971e-02, 3.8182e-08, 2.9422e-07, 9.6702e-03,\n",
      "         1.1475e-02, 7.1859e-02, 6.7002e-02, 5.3994e-02, 8.8051e-02, 3.4251e-02,\n",
      "         2.6236e-02, 1.6192e-07, 1.5511e-07, 8.8637e-08, 8.0636e-08, 3.1841e-02,\n",
      "         3.5790e-02, 3.6803e-02, 3.2425e-02, 1.6248e-02, 1.2106e-07, 2.7659e-07,\n",
      "         2.9130e-08, 8.9408e-08, 1.2030e-07, 1.1734e-07, 1.3525e-02, 3.3300e-07,\n",
      "         1.2917e-02, 5.3395e-07, 1.1759e-07, 4.0016e-07, 9.9594e-08, 1.7200e-07,\n",
      "         3.8775e-07, 1.1790e-07, 1.4348e-07, 7.0833e-08, 2.2777e-07, 1.1342e-07,\n",
      "         1.9257e-07, 2.9208e-07, 8.9941e-08, 1.3111e-07, 8.6358e-08, 1.6820e-07,\n",
      "         8.2647e-08, 1.5185e-07, 1.8473e-07, 3.9428e-07, 2.4824e-07, 1.0414e-07,\n",
      "         5.1692e-08, 2.4777e-07, 3.9921e-07, 1.7672e-07, 2.6177e-07, 4.2338e-07,\n",
      "         1.6223e-07, 1.1988e-07, 1.4646e-07, 1.3268e-07, 1.4637e-07, 9.3847e-08,\n",
      "         2.7545e-02, 3.0591e-07, 1.9360e-07, 2.9902e-07, 8.9704e-08, 9.6799e-03,\n",
      "         1.6387e-07, 2.0289e-07, 8.8901e-08, 1.9395e-03, 2.4940e-02, 1.2828e-02,\n",
      "         3.7433e-02, 8.4066e-02, 3.5544e-02, 1.5801e-02, 5.7693e-08, 2.1357e-07,\n",
      "         1.5827e-07, 2.5910e-07, 9.7736e-03, 8.4530e-02, 5.7535e-02, 8.4179e-02,\n",
      "         7.8086e-03, 5.1414e-02, 1.2854e-02, 1.4959e-07, 4.5054e-07, 1.4550e-07,\n",
      "         9.6438e-08, 7.8189e-08, 9.0969e-02, 9.4030e-02, 2.2397e-02, 1.5506e-02,\n",
      "         2.0275e-08, 9.2472e-08, 6.4465e-08, 1.4132e-07, 2.0542e-07, 1.5680e-07,\n",
      "         6.3201e-02, 8.2117e-02, 1.0368e-02, 1.9790e-02, 1.9446e-07, 3.7590e-07,\n",
      "         1.0109e-07, 1.8917e-07, 1.7832e-07, 2.7198e-02, 9.4635e-02, 2.8607e-02,\n",
      "         8.6492e-02, 3.8181e-08, 9.9300e-08, 6.2357e-08, 1.1075e-07, 1.7868e-07,\n",
      "         6.5871e-07, 1.1682e-02, 2.8797e-02, 3.5721e-02, 2.8741e-02, 6.2111e-03,\n",
      "         1.3489e-07, 5.9881e-08, 2.8606e-07, 7.6495e-08, 1.5998e-03, 9.8552e-08,\n",
      "         1.5527e-02, 1.2191e-02, 3.1257e-02, 7.7918e-03, 6.0434e-08, 5.4434e-08,\n",
      "         1.7986e-07, 1.6320e-07, 1.8143e-07, 2.0815e-07, 2.8394e-02, 1.0008e-02,\n",
      "         5.6387e-03, 1.1537e-07, 1.9479e-07, 1.9251e-07, 1.4309e-07, 2.3091e-07,\n",
      "         1.2194e-07, 1.3288e-07, 1.3181e-07, 1.3277e-07, 1.8928e-07, 9.5594e-08,\n",
      "         1.4290e-07, 2.9304e-07, 1.0220e-07, 1.9083e-07, 2.5675e-07, 1.0518e-07,\n",
      "         7.5294e-08, 1.8651e-07, 1.8049e-07, 9.4180e-08, 1.9185e-07, 3.0130e-07,\n",
      "         3.1802e-07, 2.3129e-07, 8.8920e-08, 3.4030e-07, 1.0319e-07, 7.4618e-08,\n",
      "         1.9507e-07, 9.4441e-08, 1.5753e-07, 1.5221e-07, 1.9934e-01, 8.0173e-02,\n",
      "         4.8255e-02, 4.1548e-08, 1.6409e-02, 1.9174e-02, 1.0006e-02, 5.0580e-02,\n",
      "         8.8081e-02, 2.5107e-01, 3.8197e-02, 1.7565e-07, 1.5532e-02, 1.5411e-07,\n",
      "         1.5012e-07, 7.3807e-08, 2.7357e-07, 9.5649e-08, 1.3623e-02, 5.6013e-02,\n",
      "         1.0055e-02, 1.5386e-07, 3.9283e-07, 2.7399e-07, 1.5781e-07, 2.0770e-07,\n",
      "         6.6727e-08, 2.3641e-08, 1.5257e-07, 1.4148e-02, 1.4541e-02, 3.0807e-03,\n",
      "         7.8622e-08, 2.2690e-07, 7.5031e-08, 1.7282e-07, 4.7376e-08, 1.7602e-07,\n",
      "         4.9841e-08, 1.3466e-02, 1.5005e-02, 2.9993e-07, 1.2857e-07, 1.1443e-07,\n",
      "         1.2517e-02, 9.0587e-08, 5.5516e-07, 1.6767e-07, 3.3777e-07, 1.0055e-02,\n",
      "         2.9425e-02, 7.1100e-08, 8.3257e-08, 2.7587e-07, 1.6768e-07, 1.0641e-02,\n",
      "         1.6817e-02, 5.9398e-08, 1.3291e-07, 2.2261e-02, 1.1043e-02, 6.5858e-03,\n",
      "         5.5472e-08, 3.0153e-07, 7.8806e-08, 1.9759e-07, 1.6003e-07, 3.1330e-08,\n",
      "         1.4236e-07, 1.1390e-02, 1.6310e-02, 9.0920e-08, 2.3963e-07, 4.2801e-07,\n",
      "         2.5265e-07, 1.9590e-07, 1.4242e-07, 9.1771e-08, 4.0445e-08, 7.7191e-03,\n",
      "         3.0911e-02, 4.1190e-08, 1.3520e-07, 3.4736e-07, 1.6101e-07, 1.4333e-07,\n",
      "         1.2410e-07, 1.8165e-07, 1.6085e-07, 1.3031e-02, 1.5821e-02, 2.5296e-07,\n",
      "         1.4666e-02, 2.0314e-07, 2.8571e-07, 1.2490e-07, 4.3137e-08, 6.0188e-08,\n",
      "         1.4317e-02, 1.7918e-02, 6.6783e-02, 1.4975e-02, 1.2047e-07, 1.9797e-07,\n",
      "         1.6333e-07, 3.9231e-07, 1.5337e-02, 1.2500e-02, 1.2813e-02, 5.0802e-02,\n",
      "         4.4089e-02, 7.7913e-03, 1.3168e-02, 1.3067e-07, 1.5030e-07, 1.1912e-02,\n",
      "         1.3073e-02, 2.0948e-02, 9.7974e-03, 5.2332e-02, 8.3831e-08, 4.7307e-08,\n",
      "         2.2454e-07, 9.4375e-08, 1.3929e-07, 9.0162e-08, 5.0653e-08, 2.8720e-07,\n",
      "         1.5497e-07, 3.9259e-07, 4.6353e-08, 1.5372e-07, 6.1198e-08, 1.0663e-07,\n",
      "         2.4345e-07, 2.4080e-07, 3.3372e-07, 2.0738e-07, 2.6862e-07, 2.1645e-07,\n",
      "         2.1196e-07, 1.0086e-07, 2.1121e-07, 5.0123e-08, 1.0666e-07, 3.6091e-07,\n",
      "         2.5678e-07, 1.1578e-07, 8.9414e-08, 1.8221e-07, 9.9403e-08, 2.7863e-07,\n",
      "         2.7686e-02, 2.9548e-02, 3.0121e-02, 7.8582e-03, 3.7116e-02, 1.3444e-02,\n",
      "         1.1729e-07, 3.9523e-08, 1.0226e-07, 8.5026e-03, 9.6239e-02, 3.0672e-02,\n",
      "         2.1787e-02, 1.8974e-02, 8.5861e-02, 7.8302e-02, 1.0230e-02, 1.5046e-07,\n",
      "         1.5396e-02, 1.7269e-02, 1.6298e-01, 1.0230e-01, 3.1353e-02, 3.7996e-02,\n",
      "         1.2098e-01, 9.0086e-02, 2.5724e-02, 4.5051e-07, 2.5780e-02, 2.6510e-02,\n",
      "         1.4559e-01, 1.1246e-01, 3.4754e-02, 4.6249e-02, 1.2035e-01, 1.2067e-01,\n",
      "         2.5588e-02, 8.6276e-03, 3.3706e-02, 3.0478e-02, 1.5869e-01, 1.1177e-01,\n",
      "         4.4154e-02, 4.2500e-02, 1.4923e-01, 1.2083e-01, 7.5796e-02, 1.2328e-02,\n",
      "         1.3549e-02, 3.5163e-02, 1.5383e-01, 9.3409e-02, 2.5809e-02, 2.9091e-02,\n",
      "         1.5561e-01, 1.2138e-01, 6.5307e-02, 8.8025e-03, 4.0264e-07, 9.7961e-03,\n",
      "         1.3015e-01, 9.9335e-02, 4.0196e-02, 5.6406e-02, 1.4857e-01, 7.2470e-02,\n",
      "         2.8101e-02, 1.3357e-07, 1.8421e-07, 5.4593e-03, 9.0420e-02, 8.0220e-02,\n",
      "         2.9812e-02, 2.9677e-02, 1.1514e-01, 4.2313e-02, 2.1817e-02, 1.6570e-07,\n",
      "         8.5738e-08, 7.3853e-08, 1.2674e-02, 5.6080e-03, 8.7665e-03, 9.5429e-03,\n",
      "         1.2951e-02, 1.1917e-07, 2.5860e-07, 2.1814e-07, 1.1778e-07, 2.7521e-07,\n",
      "         1.2270e-07, 7.3718e-08, 1.2385e-07, 2.5426e-07, 9.4975e-08, 3.5785e-07,\n",
      "         1.6527e-07, 2.0199e-07, 1.3928e-07, 2.2641e-07, 5.9512e-08, 1.4026e-02,\n",
      "         1.5190e-02, 1.4797e-02, 1.2041e-02, 1.5390e-02, 1.1796e-02, 1.3338e-02,\n",
      "         5.5861e-14, 1.9660e-07, 2.3928e-07, 6.8446e-08, 1.3536e-07, 1.5485e-07,\n",
      "         1.0390e-07, 2.5644e-07, 2.2440e-07, 1.1453e-02, 5.1986e-10, 1.5253e-07,\n",
      "         2.6385e-07, 2.3465e-07, 1.2948e-07, 8.6149e-08, 6.7487e-08, 1.2926e-07,\n",
      "         1.4199e-07, 1.7708e-02, 3.7392e-12, 9.0262e-08, 3.2183e-14, 2.6745e-14,\n",
      "         4.4960e-10, 2.9164e-06, 8.7346e-02, 8.1271e-02, 3.5875e-02, 6.4894e-02,\n",
      "         7.5935e-15, 1.4902e-15, 3.0438e-16, 5.0223e-15, 8.7038e-08, 4.6864e-02,\n",
      "         9.1249e-02, 2.1802e-01, 9.9766e-02, 7.5841e-02, 8.8895e-14, 8.6819e-16,\n",
      "         5.8140e-16, 3.1277e-15, 9.9166e-08, 1.9745e-10, 1.9023e-01, 2.9387e-01,\n",
      "         9.7484e-02, 4.4044e-02, 1.5139e-12, 2.7717e-16, 3.7876e-16, 6.3562e-15,\n",
      "         6.3778e-08, 3.0966e-02, 1.3883e-01, 3.4878e-01, 1.5432e-01, 5.3092e-02,\n",
      "         1.5315e-12, 3.8511e-15, 6.4564e-16, 3.6924e-15, 6.2358e-08, 2.3063e-14,\n",
      "         1.5271e-01, 2.6995e-01, 2.1874e-01, 4.7666e-02, 2.0783e-12, 7.8794e-16,\n",
      "         7.4021e-16, 1.4558e-14, 5.0151e-08, 5.7738e-13, 1.5000e-01, 2.7386e-01,\n",
      "         1.7956e-01, 1.6024e-02, 9.5514e-12, 5.1758e-16, 2.2281e-15, 1.7781e-14,\n",
      "         1.2523e-03, 6.7961e-13, 1.2609e-01, 2.1973e-01, 8.1347e-02, 5.4768e-02,\n",
      "         6.3173e-13, 2.8709e-13, 5.3570e-15, 7.4992e-15, 9.4524e-04, 2.3914e-10,\n",
      "         1.1474e-01, 1.4057e-01, 3.7466e-02, 3.1449e-09, 1.9154e-10, 1.7152e-07,\n",
      "         1.8562e-12, 3.3736e-13, 9.4425e-03, 1.9931e-07, 1.7903e-08, 4.1031e-02,\n",
      "         5.1856e-08, 7.0118e-11, 1.1407e-07, 6.9697e-08, 1.9776e-07, 3.0981e-07,\n",
      "         2.5947e-07, 9.9997e-08, 4.9098e-08, 7.6704e-08, 1.1383e-07, 6.0050e-11,\n",
      "         1.1989e-07, 2.3651e-07, 5.9740e-08, 7.3135e-08, 5.9880e-07, 1.3451e-07,\n",
      "         1.9279e-07, 4.8840e-08, 2.2367e-07, 3.6652e-08, 1.3364e-15, 5.2433e-16,\n",
      "         1.6401e-16, 3.8597e-15, 1.7744e-15, 3.7999e-16, 4.8973e-16, 7.5083e-15,\n",
      "         2.2130e-15, 1.3177e-15, 2.0992e-15, 8.5894e-08, 7.0496e-12, 3.6361e-15,\n",
      "         9.1710e-15, 6.0733e-14, 4.4533e-15, 3.4088e-11, 1.8597e-11, 4.7649e-15,\n",
      "         2.6988e-15, 1.5530e-11, 2.9612e-14, 2.9172e-15, 4.0586e-15, 1.5072e-14,\n",
      "         6.4058e-15, 1.6191e-15, 7.2500e-11, 6.8254e-14, 2.0309e-15, 3.6935e-11,\n",
      "         1.3425e-14, 9.1082e-03, 2.2186e-15, 8.2310e-15, 1.5080e-11, 1.5378e-14,\n",
      "         1.0163e-10, 2.9031e-13, 5.4491e-13, 1.1134e-09, 8.6931e-15, 1.7825e-11,\n",
      "         1.5513e-13, 3.6607e-14, 7.0223e-16, 3.9626e-15, 4.2700e-10, 2.6512e-13,\n",
      "         3.4632e-13, 4.2628e-07, 1.8270e-14, 5.7076e-10, 9.5495e-13, 4.9847e-09,\n",
      "         1.1173e-01, 2.3227e-09, 1.4967e-02, 3.7308e-14, 3.0657e-13, 8.6329e-06,\n",
      "         1.6149e-05, 1.9450e-10, 1.0557e-12, 6.3905e-08, 1.1901e-01, 3.0659e-02,\n",
      "         7.3229e-12, 2.9310e-14, 8.4540e-14, 6.8806e-10, 2.1871e-11, 2.5571e-10,\n",
      "         1.7795e-10, 4.5261e-07, 5.7225e-12, 3.9805e-02, 1.5170e-04, 5.9265e-13,\n",
      "         1.3048e-14, 1.7964e-02, 2.9336e-02, 7.3733e-02, 9.0974e-02, 8.6865e-02,\n",
      "         1.4640e-01, 2.5300e-02, 7.3624e-03, 1.0928e-13, 6.8365e-15, 4.7186e-03,\n",
      "         2.1248e-02, 4.0145e-02, 4.9109e-02, 4.3372e-02, 8.2926e-02, 2.6219e-02,\n",
      "         5.4169e-04, 2.9519e-15, 1.2792e-15, 3.6785e-13, 7.0231e-03, 5.3325e-03,\n",
      "         4.4934e-02, 3.7748e-02, 4.5078e-09, 6.3482e-11, 4.5365e-15, 6.0154e-16,\n",
      "         3.1638e-14, 3.7607e-13, 3.5607e-10, 2.1608e-12, 5.5408e-13, 3.4889e-14,\n",
      "         1.4321e-11, 9.7262e-15, 4.2261e-15, 3.5299e-15, 2.2966e-07, 3.4529e-07,\n",
      "         3.4460e-10, 1.5939e-02, 3.9803e-02, 3.7975e-02, 4.1369e-02, 3.6453e-02,\n",
      "         1.2630e-02, 1.1618e-02]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    z = torch.randn(1, z_dim).cuda()\n",
    "    sample = vae.decoder(z).cuda()\n",
    "    \n",
    "    torch.set_printoptions(profile=\"full\")    \n",
    "    data = sample[0]\n",
    "    \n",
    "    output_tensor = torch.zeros((17, 13, 10))\n",
    "    \n",
    "    # reshape sample(1*200) -> output_tensor(17, 13, 10)\n",
    "    for i, batch in enumerate(sample):\n",
    "        i = 0\n",
    "        for depth in range(17):\n",
    "            for col in range(13):\n",
    "                for row in range(10):\n",
    "                    #print(\"depth, col, row: \" + str(row)+\", \" + str(col) +\", \", str(depth))\n",
    "                    data = batch[i]\n",
    "                    i += 1\n",
    "                    if data >= 0.15:\n",
    "                        output_tensor[depth][col][row] = 1\n",
    "                                             \n",
    "    \n",
    "    object_dict = {\n",
    "        0: 'WB',\n",
    "        1: 'PR',\n",
    "        2: 'T2',\n",
    "        3: 'TV',\n",
    "        4: 'B4',\n",
    "        5: 'PP',\n",
    "        6: 'MB',\n",
    "        7: 'CC',\n",
    "        8: 'CS',\n",
    "        9: 'T3',\n",
    "        10: 'B2',\n",
    "        11: 'LP',\n",
    "        12: 'MP',\n",
    "        13: 'LB',\n",
    "        14: 'DC'\n",
    "    }\n",
    "\n",
    "\n",
    "    room = [['--']*10 for i in range(13)]\n",
    "    for col in range(13):\n",
    "        for row in range(10):\n",
    "            object_duplicate_flage = 0\n",
    "            for depth in range(15):\n",
    "                data = output_tensor[depth][col][row]\n",
    "                \n",
    "                if data == 1:\n",
    "                    object_duplicate_flage += 1\n",
    "                    room[col][row] = object_dict[depth]\n",
    "                    \n",
    "            if object_duplicate_flage > 1:\n",
    "                print(f\"dup in {col}, {row}\")\n",
    "    \n",
    "    for col in range(13):\n",
    "        print(room[col])\n",
    "        \n",
    "        \n",
    "    print(sample)\n",
    "                    \n",
    "    # print room with object\n",
    "    # WB: Whiteboard\n",
    "    # PR: Projector Screen\n",
    "    # T2: Chippendale Table (2x3)\n",
    "    # TV: TV (Flatscreen)\n",
    "    # B4: Bookshelf (2x4)\n",
    "    # PP: Potted Plant (Spikey)\n",
    "    # MB: Mod Chair\n",
    "    # CC: Captainâ€™s Chair\n",
    "    # CS: Chair (Simple)\n",
    "    # T3: Chippendale Table (3x3)\n",
    "    # B2: Bookshelf [Tall] (1x2)\n",
    "    # LP: Laptop\n",
    "    # MP: Microphone\n",
    "    # LB: Lucky Bamboo\n",
    "    # DC: Dining Chair (Square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad421d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1783de79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab6c717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
