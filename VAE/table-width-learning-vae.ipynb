{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95e75369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prerequisites\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ef4cef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_table_body(width, height, pos_x, pos_y, data):\n",
    "    for w in range(width):\n",
    "        for h in range(height + 1):\n",
    "            x = pos_x + w\n",
    "            y = pos_y + h\n",
    "            data[6][y][x] = 1\n",
    "            data[encode_size - 1][y][x] = -1\n",
    "#     print(\"data\")\n",
    "#     print(f\"({x}, {y})\")\n",
    "#     print(data[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "663d5955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 120\n",
      "datasets number = 120\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import urllib\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/Chaoyuuu/Gather-Town-Datasets/master/datasets-real-room.json\"\n",
    "response = urllib.request.urlopen(url)\n",
    "data = json.loads(response.read())\n",
    "data_length = len(data)\n",
    "\n",
    "count = 0\n",
    "for i in range(data_length):\n",
    "    room_id = data[i][\"id\"]\n",
    "    if \"Ning\" not in room_id and \"Han\" not in room_id: \n",
    "        count += 1\n",
    "#         print(room_id)\n",
    "        \n",
    "print(\"count: \" + str(count))\n",
    "    \n",
    "\n",
    "# table_arrangement\n",
    "encode_size = 9  # (6+1 object + 2 orientation)\n",
    "table_arrange_data = torch.zeros((count, encode_size, 13, 10)) \n",
    "table_arrange_label_dict = {\n",
    "    \"Chippendale Table (2x3)\": 0,\n",
    "    \"Chippendale Table (3x3)\": 1,\n",
    "    \"Mod Chair\": 2,\n",
    "    \"Captain's Chair\": 3,\n",
    "    \"Laptop\": 4,\n",
    "    \"Microphone\": 5,\n",
    "    \"Table body\": 6,\n",
    "}\n",
    "    \n",
    "i = -1\n",
    "for d in range(data_length):\n",
    "    room_id = data[d][\"id\"]\n",
    "    if \"Ning\" not in room_id and \"Han\" not in room_id and \"Chao\" not in room_id: \n",
    "        i += 1\n",
    "        room = data[d][\"room\"]\n",
    "\n",
    "        for k in range(len(room)):\n",
    "            object = room[k]\n",
    "            name = object[\"_name\"]\n",
    "            if name in table_arrange_label_dict:\n",
    "                label = table_arrange_label_dict[name]\n",
    "                x = object[\"x\"]\n",
    "                y = object[\"y\"]\n",
    "                orientation = object[\"orientation\"]\n",
    "\n",
    "                if label == 0:\n",
    "                    set_table_body(3, 3, x, y, table_arrange_data[i])\n",
    "                elif label == 1 and orientation == 0:\n",
    "                    set_table_body(3, 2, x, y, table_arrange_data[i])\n",
    "                elif label == 1 and orientation == 2:\n",
    "                    set_table_body(2, 3, x, y, table_arrange_data[i])\n",
    "                elif label == 1:\n",
    "                    print(\"label with odd orientaion !!\")\n",
    "                else:\n",
    "                    if table_arrange_data[i][6][y][x] == 1:\n",
    "                        table_arrange_data[i][6][y][x] =0\n",
    "                        table_arrange_data[i][encode_size - 1][y][x] = 0\n",
    "                    \n",
    "                table_arrange_data[i][label][y][x] = 1\n",
    "\n",
    "                if orientation == 0:\n",
    "                    table_arrange_data[i][encode_size - 1][y][x] = -1\n",
    "                elif orientation == 1:\n",
    "                    table_arrange_data[i][encode_size - 2][y][x] = -1\n",
    "                elif orientation == 2:\n",
    "                    table_arrange_data[i][encode_size - 1][y][x] = 1\n",
    "                else:\n",
    "                    table_arrange_data[i][encode_size - 2][y][x] = 1\n",
    "                    \n",
    "# print(table_arrange_data[0][6])\n",
    "\n",
    "\n",
    "z_dim = 2\n",
    "x_dim = encode_size*13*10\n",
    "bs = 60\n",
    "epoch_round = 13\n",
    "print(\"datasets number = \" + str(count))\n",
    "\n",
    "train_loader = DataLoader(dataset=table_arrange_data, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c231464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_dim, h_dim1, h_dim2, z_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # encoder part\n",
    "        self.fc1 = nn.Linear(x_dim, h_dim1)\n",
    "        self.fc2 = nn.Linear(h_dim1, h_dim2)\n",
    "        self.fc31 = nn.Linear(h_dim2, z_dim)\n",
    "        self.fc32 = nn.Linear(h_dim2, z_dim)\n",
    "        # decoder part\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim2)\n",
    "        self.fc5 = nn.Linear(h_dim2, h_dim1)\n",
    "        self.fc6 = nn.Linear(h_dim1, x_dim)\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        return self.fc31(h), self.fc32(h) # mu, log_var\n",
    "    \n",
    "    def sampling(self, mu, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add_(mu) # return z sample\n",
    "        \n",
    "    def decoder(self, z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        h = F.relu(self.fc5(h))\n",
    "        return torch.sigmoid(self.fc6(h)) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encoder(x.view(-1, x_dim))\n",
    "        z = self.sampling(mu, log_var)\n",
    "        return self.decoder(z), mu, log_var\n",
    "\n",
    "# build model\n",
    "vae = VAE(x_dim=x_dim, h_dim1= 256, h_dim2=64, z_dim=z_dim)\n",
    "if torch.cuda.is_available():\n",
    "    vae.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a5270d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (fc1): Linear(in_features=1170, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (fc31): Linear(in_features=64, out_features=2, bias=True)\n",
       "  (fc32): Linear(in_features=64, out_features=2, bias=True)\n",
       "  (fc4): Linear(in_features=2, out_features=64, bias=True)\n",
       "  (fc5): Linear(in_features=64, out_features=256, bias=True)\n",
       "  (fc6): Linear(in_features=256, out_features=1170, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "466a095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(vae.parameters())\n",
    "# return reconstruction error + KL divergence losses\n",
    "def loss_function(recon_x, x, mu, log_var):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, x_dim), reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37bcd4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    vae.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        data = data.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        print(list(data.size())) # [81, 17, 13, 10]\n",
    "        \n",
    "        recon_batch, mu, log_var = vae(data) #torch.float32\n",
    "        loss = loss_function(recon_batch, data, mu, log_var)\n",
    "        \n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item() / len(data)))\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c10d7873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    vae.eval()\n",
    "    test_loss= 0\n",
    "    with torch.no_grad():\n",
    "        for data, _ in test_loader:\n",
    "            data = data.cuda()\n",
    "            recon, mu, log_var = vae(data)\n",
    "            \n",
    "            # sum up batch loss\n",
    "            test_loss += loss_function(recon, data, mu, log_var).item()\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55d9592d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60, 9, 13, 10]\n",
      "Train Epoch: 1 [0/120 (0%)]\tLoss: 812.920117\n",
      "[60, 9, 13, 10]\n",
      "====> Epoch: 1 Average loss: 802.0398\n",
      "[60, 9, 13, 10]\n",
      "Train Epoch: 2 [0/120 (0%)]\tLoss: 768.929753\n",
      "[60, 9, 13, 10]\n",
      "====> Epoch: 2 Average loss: 757.5072\n",
      "[60, 9, 13, 10]\n",
      "Train Epoch: 3 [0/120 (0%)]\tLoss: 722.076042\n",
      "[60, 9, 13, 10]\n",
      "====> Epoch: 3 Average loss: 708.9895\n",
      "[60, 9, 13, 10]\n",
      "Train Epoch: 4 [0/120 (0%)]\tLoss: 661.851693\n",
      "[60, 9, 13, 10]\n",
      "====> Epoch: 4 Average loss: 647.1063\n",
      "[60, 9, 13, 10]\n",
      "Train Epoch: 5 [0/120 (0%)]\tLoss: 592.036523\n",
      "[60, 9, 13, 10]\n",
      "====> Epoch: 5 Average loss: 571.7993\n",
      "[60, 9, 13, 10]\n",
      "Train Epoch: 6 [0/120 (0%)]\tLoss: 517.641178\n",
      "[60, 9, 13, 10]\n",
      "====> Epoch: 6 Average loss: 494.5650\n",
      "[60, 9, 13, 10]\n",
      "Train Epoch: 7 [0/120 (0%)]\tLoss: 426.699154\n",
      "[60, 9, 13, 10]\n",
      "====> Epoch: 7 Average loss: 404.7923\n",
      "[60, 9, 13, 10]\n",
      "Train Epoch: 8 [0/120 (0%)]\tLoss: 353.993815\n",
      "[60, 9, 13, 10]\n",
      "====> Epoch: 8 Average loss: 325.4342\n",
      "[60, 9, 13, 10]\n",
      "Train Epoch: 9 [0/120 (0%)]\tLoss: 258.591878\n",
      "[60, 9, 13, 10]\n",
      "====> Epoch: 9 Average loss: 240.3248\n",
      "[60, 9, 13, 10]\n",
      "Train Epoch: 10 [0/120 (0%)]\tLoss: 184.261572\n",
      "[60, 9, 13, 10]\n",
      "====> Epoch: 10 Average loss: 162.4433\n",
      "[60, 9, 13, 10]\n",
      "Train Epoch: 11 [0/120 (0%)]\tLoss: 107.072721\n",
      "[60, 9, 13, 10]\n",
      "====> Epoch: 11 Average loss: 105.1633\n",
      "[60, 9, 13, 10]\n",
      "Train Epoch: 12 [0/120 (0%)]\tLoss: 71.905998\n",
      "[60, 9, 13, 10]\n",
      "====> Epoch: 12 Average loss: 56.8126\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epoch_round):\n",
    "    train(epoch)\n",
    "#     test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba9e979e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['  ', '  ', '  ', '  ', '  ', '  ', '  ', '  ', '  ', '  ']\n",
      "['  ', '  ', '  ', '  ', '  ', '  ', '  ', '  ', '  ', '  ']\n",
      "['  ', '  ', '  ', '  ', '  ', '  ', '  ', '  ', '  ', '  ']\n",
      "['  ', '  ', '  ', '  ', '  ', '--', '  ', '  ', '  ', '  ']\n",
      "['  ', '  ', '  ', '  ', '--', '--', '--', '  ', '  ', '  ']\n",
      "['  ', '  ', '  ', '  ', '--', '--', '--', '  ', '  ', '  ']\n",
      "['  ', '  ', '  ', '  ', '--', '--', '--', '  ', '  ', '  ']\n",
      "['  ', '  ', '  ', '--', '--', '--', '--', '  ', '  ', '  ']\n",
      "['  ', '  ', '  ', '--', '--', '--', '--', '  ', '  ', '  ']\n",
      "['  ', '  ', '  ', '  ', '--', '--', '--', '  ', '  ', '  ']\n",
      "['  ', '  ', '  ', '  ', '  ', '  ', '  ', '  ', '  ', '  ']\n",
      "['  ', '  ', '  ', '  ', '  ', '  ', '  ', '  ', '  ', '  ']\n",
      "['  ', '  ', 'MC', '  ', '  ', '  ', '  ', '  ', '  ', '  ']\n",
      "tensor([[0.0154, 0.0230, 0.0232, 0.0263, 0.0532, 0.0270, 0.0276, 0.0160, 0.0360,\n",
      "         0.0349, 0.0208, 0.0404, 0.0468, 0.0282, 0.0185, 0.0498, 0.0235, 0.0231,\n",
      "         0.0227, 0.0223, 0.0479, 0.0278, 0.0289, 0.0361, 0.0308, 0.0278, 0.0428,\n",
      "         0.0266, 0.0378, 0.0314, 0.0539, 0.0206, 0.0381, 0.0366, 0.0524, 0.0343,\n",
      "         0.0314, 0.0296, 0.0495, 0.0176, 0.0609, 0.0218, 0.0151, 0.0250, 0.0585,\n",
      "         0.0313, 0.0365, 0.0361, 0.0300, 0.0355, 0.0326, 0.0345, 0.0233, 0.0425,\n",
      "         0.0225, 0.0301, 0.0165, 0.0279, 0.0214, 0.0589, 0.0365, 0.0466, 0.0216,\n",
      "         0.0429, 0.0230, 0.0267, 0.0606, 0.0292, 0.0430, 0.0234, 0.0207, 0.0253,\n",
      "         0.0286, 0.0796, 0.0334, 0.0455, 0.0396, 0.0569, 0.0188, 0.0289, 0.0280,\n",
      "         0.0158, 0.0441, 0.0275, 0.0514, 0.0917, 0.0349, 0.0247, 0.0232, 0.0533,\n",
      "         0.0360, 0.0248, 0.0309, 0.0311, 0.0362, 0.0309, 0.0481, 0.0454, 0.0487,\n",
      "         0.0382, 0.0295, 0.0532, 0.0414, 0.0431, 0.0330, 0.0466, 0.0461, 0.0235,\n",
      "         0.0349, 0.0235, 0.0289, 0.0517, 0.0128, 0.0281, 0.0297, 0.0357, 0.0366,\n",
      "         0.0184, 0.0509, 0.0226, 0.0222, 0.0471, 0.0341, 0.0294, 0.0491, 0.0377,\n",
      "         0.0319, 0.0365, 0.0313, 0.0255, 0.0232, 0.0485, 0.0507, 0.0305, 0.0197,\n",
      "         0.0202, 0.0229, 0.0423, 0.0481, 0.0333, 0.0388, 0.0340, 0.0438, 0.0485,\n",
      "         0.0321, 0.0272, 0.0262, 0.0497, 0.0459, 0.0741, 0.0549, 0.0405, 0.0263,\n",
      "         0.0255, 0.0546, 0.0265, 0.0253, 0.0312, 0.0347, 0.0249, 0.0267, 0.0395,\n",
      "         0.0358, 0.0457, 0.0282, 0.0212, 0.0220, 0.0354, 0.0475, 0.0320, 0.0441,\n",
      "         0.0464, 0.0549, 0.0451, 0.0256, 0.0329, 0.0223, 0.0288, 0.0471, 0.0314,\n",
      "         0.0309, 0.0273, 0.0270, 0.0180, 0.0407, 0.0196, 0.0336, 0.0170, 0.0545,\n",
      "         0.0254, 0.0514, 0.0296, 0.0300, 0.0260, 0.0332, 0.0331, 0.0274, 0.0480,\n",
      "         0.0433, 0.0253, 0.0332, 0.0604, 0.0393, 0.0376, 0.0268, 0.0286, 0.0390,\n",
      "         0.0339, 0.0232, 0.0306, 0.0460, 0.0243, 0.0165, 0.0311, 0.0327, 0.0389,\n",
      "         0.0277, 0.0272, 0.0220, 0.0292, 0.0349, 0.0292, 0.0217, 0.0394, 0.0404,\n",
      "         0.0367, 0.0371, 0.0233, 0.0538, 0.0260, 0.0304, 0.0516, 0.0221, 0.0313,\n",
      "         0.0233, 0.0394, 0.0278, 0.0418, 0.0184, 0.0374, 0.0418, 0.0587, 0.0400,\n",
      "         0.0354, 0.0281, 0.0242, 0.0311, 0.0546, 0.0201, 0.0147, 0.0254, 0.0283,\n",
      "         0.0190, 0.0183, 0.0325, 0.0322, 0.0391, 0.0471, 0.0305, 0.0412, 0.0474,\n",
      "         0.0119, 0.0409, 0.0171, 0.0293, 0.0353, 0.0307, 0.0299, 0.0173, 0.0326,\n",
      "         0.0524, 0.0233, 0.0295, 0.0248, 0.0420, 0.0288, 0.0258, 0.0317, 0.0448,\n",
      "         0.0214, 0.0591, 0.0296, 0.0236, 0.0170, 0.0220, 0.0608, 0.0226, 0.0357,\n",
      "         0.0459, 0.0269, 0.0213, 0.0250, 0.0330, 0.0488, 0.0367, 0.0941, 0.0321,\n",
      "         0.0361, 0.0224, 0.0268, 0.0384, 0.0360, 0.0371, 0.0253, 0.0330, 0.0207,\n",
      "         0.0320, 0.0256, 0.0505, 0.0265, 0.0270, 0.0176, 0.0177, 0.0194, 0.0375,\n",
      "         0.0245, 0.0329, 0.0265, 0.0331, 0.0511, 0.0242, 0.0334, 0.0297, 0.0242,\n",
      "         0.0281, 0.0234, 0.0250, 0.0279, 0.0267, 0.0309, 0.0333, 0.0286, 0.0293,\n",
      "         0.0466, 0.0178, 0.0364, 0.0283, 0.0382, 0.0468, 0.0370, 0.0350, 0.0304,\n",
      "         0.0433, 0.0236, 0.0307, 0.0202, 0.0439, 0.0221, 0.0204, 0.0285, 0.0084,\n",
      "         0.0472, 0.0293, 0.0392, 0.0426, 0.0231, 0.0330, 0.0339, 0.0202, 0.0324,\n",
      "         0.0167, 0.0344, 0.0568, 0.0234, 0.0323, 0.0334, 0.0297, 0.0175, 0.0313,\n",
      "         0.0487, 0.0469, 0.0261, 0.0330, 0.0303, 0.0225, 0.0256, 0.0238, 0.0331,\n",
      "         0.0212, 0.0331, 0.0309, 0.0219, 0.1145, 0.0435, 0.0343, 0.0659, 0.0351,\n",
      "         0.0292, 0.0258, 0.0395, 0.0221, 0.0244, 0.0412, 0.0537, 0.0491, 0.0915,\n",
      "         0.0281, 0.0289, 0.0310, 0.0400, 0.0556, 0.0327, 0.0435, 0.0300, 0.0177,\n",
      "         0.0562, 0.0274, 0.0335, 0.0451, 0.0206, 0.0279, 0.0302, 0.0309, 0.0631,\n",
      "         0.0377, 0.0317, 0.0368, 0.0335, 0.0273, 0.0375, 0.0433, 0.0210, 0.0393,\n",
      "         0.0245, 0.0289, 0.0384, 0.0249, 0.0398, 0.0293, 0.0363, 0.0374, 0.0220,\n",
      "         0.0373, 0.0291, 0.0268, 0.0337, 0.0311, 0.0333, 0.0195, 0.0434, 0.0468,\n",
      "         0.0283, 0.0141, 0.0373, 0.0245, 0.0307, 0.0337, 0.0169, 0.0213, 0.0450,\n",
      "         0.0212, 0.0155, 0.0201, 0.0371, 0.0379, 0.0250, 0.0182, 0.0623, 0.0263,\n",
      "         0.0259, 0.0315, 0.0216, 0.0153, 0.0245, 0.0296, 0.0218, 0.0243, 0.0426,\n",
      "         0.0528, 0.0149, 0.0314, 0.0400, 0.0308, 0.0232, 0.0215, 0.0218, 0.0479,\n",
      "         0.0339, 0.0300, 0.0411, 0.0250, 0.0347, 0.0437, 0.0139, 0.0340, 0.0525,\n",
      "         0.0325, 0.0235, 0.0447, 0.0434, 0.0415, 0.0434, 0.0384, 0.0177, 0.0354,\n",
      "         0.0376, 0.0210, 0.0365, 0.0381, 0.0329, 0.0394, 0.0603, 0.0153, 0.0241,\n",
      "         0.0280, 0.0237, 0.0558, 0.0249, 0.0297, 0.0353, 0.0215, 0.0667, 0.0199,\n",
      "         0.0351, 0.0358, 0.0324, 0.0420, 0.0265, 0.0225, 0.0205, 0.0288, 0.0414,\n",
      "         0.0314, 0.0190, 0.0296, 0.0283, 0.0278, 0.0462, 0.0315, 0.0412, 0.0214,\n",
      "         0.0402, 0.0283, 0.0455, 0.0405, 0.0412, 0.0405, 0.0493, 0.0127, 0.0251,\n",
      "         0.0494, 0.0243, 0.0378, 0.0373, 0.0424, 0.0304, 0.0234, 0.0463, 0.0385,\n",
      "         0.0294, 0.0427, 0.0620, 0.0295, 0.0551, 0.0481, 0.0210, 0.0347, 0.0327,\n",
      "         0.0309, 0.0344, 0.0271, 0.0418, 0.0374, 0.0428, 0.0469, 0.0333, 0.0378,\n",
      "         0.0425, 0.0354, 0.0432, 0.0380, 0.0254, 0.0321, 0.0587, 0.0593, 0.0357,\n",
      "         0.0496, 0.0340, 0.0227, 0.0257, 0.0277, 0.0329, 0.0739, 0.0202, 0.0365,\n",
      "         0.0326, 0.0309, 0.0491, 0.0260, 0.0256, 0.0352, 0.0183, 0.0335, 0.0255,\n",
      "         0.0436, 0.0405, 0.0240, 0.0304, 0.0275, 0.0167, 0.0212, 0.0127, 0.0230,\n",
      "         0.0178, 0.0491, 0.0584, 0.0515, 0.0555, 0.0254, 0.0364, 0.0497, 0.0366,\n",
      "         0.0250, 0.0264, 0.0160, 0.0210, 0.0301, 0.0335, 0.0440, 0.0437, 0.0202,\n",
      "         0.0705, 0.0310, 0.0322, 0.0325, 0.0200, 0.0271, 0.0152, 0.0369, 0.0476,\n",
      "         0.0325, 0.0249, 0.0235, 0.0582, 0.0728, 0.0308, 0.0385, 0.0247, 0.0246,\n",
      "         0.0623, 0.0294, 0.0558, 0.0268, 0.0249, 0.0356, 0.0197, 0.0153, 0.0191,\n",
      "         0.0346, 0.0269, 0.0212, 0.0256, 0.0199, 0.0419, 0.0253, 0.0327, 0.0505,\n",
      "         0.0224, 0.0286, 0.0675, 0.0261, 0.0303, 0.0423, 0.0392, 0.0433, 0.0221,\n",
      "         0.0266, 0.0255, 0.0330, 0.0269, 0.0573, 0.0270, 0.0461, 0.0526, 0.0297,\n",
      "         0.0214, 0.0280, 0.0303, 0.0263, 0.0444, 0.0642, 0.0261, 0.0294, 0.0236,\n",
      "         0.0657, 0.0326, 0.0313, 0.0325, 0.0360, 0.0271, 0.0256, 0.0341, 0.0179,\n",
      "         0.0380, 0.0384, 0.0324, 0.0227, 0.0253, 0.0245, 0.0304, 0.0289, 0.0434,\n",
      "         0.0329, 0.0562, 0.0482, 0.0239, 0.0420, 0.0169, 0.0390, 0.0457, 0.0334,\n",
      "         0.0299, 0.0343, 0.0374, 0.0415, 0.0356, 0.0177, 0.0180, 0.0345, 0.0465,\n",
      "         0.0254, 0.0372, 0.0298, 0.0298, 0.0407, 0.0435, 0.0343, 0.0533, 0.0363,\n",
      "         0.0171, 0.0297, 0.0505, 0.0335, 0.0445, 0.0130, 0.0244, 0.0163, 0.0240,\n",
      "         0.0185, 0.0312, 0.0143, 0.0160, 0.0397, 0.0227, 0.0520, 0.0457, 0.0194,\n",
      "         0.0202, 0.0234, 0.0208, 0.0184, 0.0362, 0.0296, 0.0319, 0.0508, 0.0374,\n",
      "         0.0201, 0.0234, 0.0319, 0.0205, 0.0357, 0.0479, 0.0552, 0.0392, 0.0209,\n",
      "         0.0380, 0.0320, 0.0295, 0.0149, 0.0344, 0.0394, 0.0339, 0.0472, 0.0221,\n",
      "         0.0606, 0.0510, 0.0289, 0.0419, 0.0434, 0.0416, 0.0508, 0.0336, 0.0385,\n",
      "         0.0178, 0.0222, 0.0169, 0.0201, 0.0403, 0.0276, 0.0411, 0.0337, 0.0502,\n",
      "         0.0269, 0.0503, 0.0221, 0.0146, 0.0395, 0.0468, 0.0442, 0.0234, 0.0515,\n",
      "         0.0207, 0.0259, 0.0527, 0.0294, 0.0897, 0.0424, 0.0344, 0.0319, 0.0253,\n",
      "         0.0336, 0.0235, 0.0463, 0.0680, 0.0998, 0.1204, 0.0548, 0.0255, 0.0572,\n",
      "         0.0493, 0.0249, 0.0334, 0.0827, 0.0473, 0.3140, 0.1928, 0.1617, 0.0585,\n",
      "         0.0327, 0.0299, 0.0387, 0.0440, 0.0396, 0.0739, 0.4671, 0.4864, 0.2450,\n",
      "         0.0410, 0.0477, 0.0305, 0.0151, 0.0298, 0.0441, 0.0943, 0.3914, 0.4230,\n",
      "         0.2639, 0.0556, 0.0319, 0.0279, 0.0499, 0.0183, 0.0388, 0.1162, 0.4367,\n",
      "         0.3761, 0.2656, 0.0660, 0.0164, 0.0270, 0.0447, 0.0192, 0.0422, 0.1000,\n",
      "         0.3690, 0.3582, 0.1737, 0.0611, 0.0256, 0.0445, 0.0523, 0.0373, 0.0339,\n",
      "         0.0523, 0.2028, 0.1947, 0.1232, 0.0320, 0.0332, 0.0502, 0.0281, 0.0408,\n",
      "         0.0612, 0.0542, 0.0559, 0.0564, 0.0334, 0.0293, 0.0233, 0.0366, 0.0194,\n",
      "         0.0517, 0.0203, 0.0293, 0.0311, 0.0202, 0.0209, 0.0482, 0.0191, 0.0403,\n",
      "         0.0204, 0.0191, 0.0169, 0.0392, 0.0342, 0.0281, 0.0163, 0.0388, 0.0271,\n",
      "         0.0467, 0.0277, 0.0307, 0.0461, 0.0351, 0.0374, 0.0300, 0.0334, 0.0340,\n",
      "         0.0382, 0.0526, 0.0596, 0.0222, 0.0228, 0.0164, 0.0307, 0.0146, 0.0253,\n",
      "         0.0186, 0.0344, 0.0372, 0.0343, 0.0358, 0.0276, 0.0360, 0.0484, 0.0218,\n",
      "         0.0315, 0.0462, 0.0360, 0.0373, 0.0179, 0.0270, 0.0516, 0.0366, 0.0503,\n",
      "         0.0434, 0.0326, 0.0523, 0.0180, 0.0399, 0.0224, 0.0492, 0.0310, 0.0241,\n",
      "         0.0289, 0.0439, 0.0210, 0.0328, 0.0175, 0.0340, 0.0277, 0.0563, 0.0272,\n",
      "         0.0468, 0.0443, 0.0175, 0.0339, 0.0264, 0.0231, 0.0261, 0.0308, 0.0615,\n",
      "         0.0306, 0.0496, 0.0356, 0.0167, 0.0365, 0.0337, 0.0307, 0.0486, 0.0254,\n",
      "         0.0400, 0.0239, 0.0416, 0.0477, 0.0293, 0.0354, 0.0189, 0.0352, 0.0360,\n",
      "         0.0380, 0.0383, 0.0391, 0.0258, 0.0243, 0.0156, 0.0255, 0.0312, 0.0333,\n",
      "         0.0469, 0.0345, 0.0327, 0.0402, 0.0233, 0.0206, 0.0554, 0.0278, 0.0309,\n",
      "         0.0213, 0.0464, 0.0493, 0.0388, 0.0329, 0.0510, 0.0303, 0.0358, 0.0179,\n",
      "         0.0481, 0.0380, 0.0784, 0.0423, 0.0273, 0.0481, 0.0456, 0.0290, 0.0282,\n",
      "         0.0188, 0.0234, 0.0636, 0.0600, 0.0373, 0.0279, 0.0267, 0.0384, 0.0127,\n",
      "         0.0329, 0.0338, 0.0182, 0.0189, 0.0336, 0.0346, 0.0330, 0.0344, 0.0381,\n",
      "         0.0503, 0.0223, 0.0234, 0.0219, 0.0357, 0.0410, 0.0210, 0.0335, 0.0491,\n",
      "         0.0271, 0.0254, 0.0340, 0.0324, 0.0161, 0.0246, 0.0163, 0.0498, 0.0430,\n",
      "         0.0293, 0.0235, 0.0538, 0.0290, 0.0308, 0.0294, 0.0301, 0.0430, 0.0482,\n",
      "         0.0125, 0.0202, 0.0267, 0.0345, 0.0131, 0.0616, 0.0148, 0.0232, 0.0478,\n",
      "         0.0654, 0.0800, 0.0213, 0.0136, 0.0237, 0.0214, 0.0233, 0.0566, 0.0274,\n",
      "         0.0301, 0.0217, 0.0222, 0.0266, 0.0186, 0.0357, 0.0296, 0.0132, 0.0123,\n",
      "         0.0396, 0.0439, 0.0180, 0.0473, 0.0180, 0.0180, 0.0202, 0.0215, 0.0216,\n",
      "         0.0333, 0.0381, 0.0471, 0.0288, 0.0424, 0.0165, 0.0153, 0.0361, 0.0242,\n",
      "         0.0270, 0.0345, 0.0495, 0.0277, 0.0289, 0.0334, 0.0140, 0.0338, 0.0213,\n",
      "         0.0266, 0.0211, 0.0228, 0.0446, 0.0242, 0.0218, 0.0227, 0.0317, 0.0395,\n",
      "         0.0253, 0.0237, 0.0259, 0.0429, 0.0504, 0.0326, 0.0306, 0.0338, 0.0212,\n",
      "         0.0315, 0.0242, 0.0286, 0.0648, 0.0193, 0.0155, 0.0259, 0.0235, 0.0472,\n",
      "         0.0287, 0.0276, 0.0260, 0.0320, 0.0282, 0.0431, 0.0314, 0.0572, 0.0280,\n",
      "         0.0463, 0.0212, 0.0490, 0.0281, 0.0232, 0.0497, 0.0184, 0.0432, 0.0253]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    z = torch.randn(1, z_dim).cuda()\n",
    "    sample = vae.decoder(z).cuda()\n",
    "    \n",
    "    torch.set_printoptions(profile=\"full\")    \n",
    "    data = sample[0]\n",
    "    \n",
    "    output_tensor = torch.zeros((encode_size, 13, 10))\n",
    "    threshold = 0.1\n",
    "    \n",
    "    # reshape sample(1*200) -> output_tensor(17, 13, 10)\n",
    "    for i, batch in enumerate(sample):\n",
    "        i = 0\n",
    "        for depth in range(encode_size):\n",
    "            for col in range(13):\n",
    "                for row in range(10):\n",
    "                    #print(\"depth, col, row: \" + str(row)+\", \" + str(col) +\", \", str(depth))\n",
    "                    data = batch[i]\n",
    "                    i += 1\n",
    "                    if data >= threshold:\n",
    "                        output_tensor[depth][col][row] = data\n",
    "                                             \n",
    "    object_dict = {\n",
    "        0: 'T2', \n",
    "        1: 'T3', \n",
    "        2: 'MC', \n",
    "        3: 'CC', \n",
    "        4: 'LP', \n",
    "        5: 'MP',\n",
    "        6: '--'\n",
    "    }\n",
    "\n",
    "\n",
    "    room = [['  ']*10 for i in range(13)]\n",
    "    for col in range(13):\n",
    "        for row in range(10):\n",
    "            object_duplicate_flage = 0\n",
    "            max_value = 0\n",
    "            max_index = -1\n",
    "            for depth in range(encode_size - 2):\n",
    "                data = output_tensor[depth][col][row]\n",
    "                \n",
    "                if data >= threshold and max_value < data:\n",
    "                    max_index = depth\n",
    "                    \n",
    "            if max_index != -1:\n",
    "                room[col][row] = object_dict[max_index]\n",
    "    \n",
    "    for col in range(13):\n",
    "        print(room[col])\n",
    "        \n",
    "        \n",
    "    print(sample)\n",
    "                    \n",
    "    # print room with object\n",
    "    # WB: Whiteboard\n",
    "    # PR: Projector Screen\n",
    "    # T2: Chippendale Table (2x3)\n",
    "    # TV: TV (Flatscreen)\n",
    "    # B4: Bookshelf (2x4)\n",
    "    # PP: Potted Plant (Spikey)\n",
    "    # MC: Mod Chair\n",
    "    # CC: Captain’s Chair\n",
    "    # CS: Chair (Simple)\n",
    "    # T3: Chippendale Table (3x3)\n",
    "    # B2: Bookshelf [Tall] (1x2)\n",
    "    # LP: Laptop\n",
    "    # MP: Microphone\n",
    "    # LB: Lucky Bamboo\n",
    "    # DC: Dining Chair (Square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f48972",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
